# slurm.conf file generated by configurator easy.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=kslhub
#ControlAddr=
#
#MailProg=/bin/mail
#MpiDefault=OpenMPI
MpiParams=ports=12000-12999
#MpiParams=ports=#-#
ProctrackType=proctrack/pgid
ReturnToService=1
SlurmctldPidFile=/var/run/slurmd/slurmctld.pid
#SlurmctldPort=6817
#SlurmdPort=6818
SlurmUser=root
SlurmdUser=root
StateSaveLocation=/var/lib/slurmd
SwitchType=switch/none
TaskPlugin=task/none
#
#
# TIMERS
#KillWait=30
#MinJobAge=300
#SlurmctldTimeout=120
#SlurmdTimeout=300
#
#
# SCHEDULING
FastSchedule=1
SchedulerType=sched/backfill
#SchedulerPort=7321
SelectType=select/cons_res
SelectTypeParameters=CR_Core
#SelectType=select/linear
KillWait=5
#UnkillableStepProgram=5
#UnkillableStepTimeout=5
#KillOnBadExit=1
#schedulerParameters=kill_invalid_depend=yes
#
#
# LOGGING AND ACCOUNTING
AccountingStorageType=accounting_storage/slurmdbd
#AccountingStoragePort=17031
AccountingStorageHost=localhost
AccountingStorageEnforce=limits
PriorityUsageResetPeriod=NONE
PriorityType=priority/multifactor
PriorityDecayHalfLife=0
ClusterName=sk
#JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/none
#SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm/slurmcltld.log
#SlurmdDebug=3
SlurmdLogFile=/var/log/slurm/slurmd.%n.log
SlurmdPidFile=/var/run/slurmd/slurmd.%n.pid
SlurmdSpoolDir=/var/spool/slurmd/slurmd.%n
#
#
# COMPUTE NODES
NodeName=c1 Port=17001 CPUs=8 Sockets=2 CoresPerSocket=4 State=UNKNOWN
NodeName=c2 Port=17002 CPUs=8 Sockets=2 CoresPerSocket=4 State=UNKNOWN
NodeName=c3 Port=17003 CPUs=8 Sockets=2 CoresPerSocket=4 State=UNKNOWN
NodeName=c4 Port=17004 CPUs=8 Sockets=2 CoresPerSocket=4 State=UNKNOWN
NodeName=c5 Port=17005 CPUs=8 Sockets=2 CoresPerSocket=4 State=UNKNOWN
#
PartitionName=debug Nodes=c[1-5] Default=NO  OverSubscribe=NO MaxTime=0:30:00 State=UP
PartitionName=day Nodes=c[1-5] Default=YES  OverSubscribe=NO  MaxTime=72:30:00 State=UP
CryptoType=crypto/munge
SallocDefaultCommand="srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --mpi=none $SHELL"
